
=======================================================
======================= START! ========================
=======================================================
Preprocessing...

Flags:
	batch_size = 100
	checkpoint_freq = 1
	custom_input = 
	embedding_size = 128
	epochs = 3
	evaluate_batch = False
	filter_sizes = 3,4,5
	load = 
	num_filters = 128
	reduced_dataset = 1
	save = True
	save_protobuf = False
	test_data_ratio = 10
	train = True
	valid_freq = 1

Dataset:
	Train set size = 1420766
	Test set size = 157862
	Vocabulary size = 274562
	Input layer size = 117
	Number of classes = 2

Output folder: /home/ubuntu/twitter-sentiment-cnn/output/run20170423-223928
Data processing OK, creating network...
Starting training...
Step 14207 of 42621 (epoch 2), validation accuracy: 0.778713, validation loss: 46.6828
Saving checkpoint...
Step 28414 of 42621 (epoch 3), validation accuracy: 0.803176, validation loss: 42.8983
Saving checkpoint...
Step 42621 of 42621 (epoch 4), validation accuracy: 0.81239, validation loss: 41.2584
Saving checkpoint...
End of training, validation accuracy: 0.812521, validation loss: 41.272
Saving checkpoint...